# SystÃ¨me de Feedback Loop - ivoire.ai

Ce document dÃ©crit le systÃ¨me d'amÃ©lioration continue du modÃ¨le basÃ© sur les retours utilisateurs.

## ğŸ¯ Vue d'ensemble

Le systÃ¨me de feedback permet aux utilisateurs de :
1. **Noter** les prÃ©dictions (1-5 Ã©toiles)
2. **Corriger** les identifications incorrectes
3. **Confirmer** les identifications correctes
4. **Commenter** pour apporter des prÃ©cisions

Ces feedbacks sont ensuite utilisÃ©s pour rÃ©-entraÃ®ner le modÃ¨le avec un poids plus Ã©levÃ© sur les corrections.

## ğŸ“Š Architecture

### 1. Collecte des Feedbacks

```
Utilisateur â†’ Frontend (FeedbackSystem) â†’ API /api/feedback â†’ FeedbackService
                                                              â†“
                                                         Stockage JSON
                                                         + Images
```

### 2. Curation

Les feedbacks sont stockÃ©s avec le statut `pending`. Un curateur peut :
- **Approuver** : Le feedback sera utilisÃ© pour l'entraÃ®nement
- **Rejeter** : Le feedback est ignorÃ© (spam, incohÃ©rent, etc.)

### 3. PrÃ©paration du Dataset

Les feedbacks approuvÃ©s sont convertis en entrÃ©es d'entraÃ®nement avec :
- **Poids 1.0** : Confirmations (prÃ©diction correcte)
- **Poids 2.0** (configurable) : Corrections (prÃ©diction incorrecte)

### 4. RÃ©-entraÃ®nement

Le script `train_with_feedback.py` :
1. Charge les donnÃ©es originales
2. Ajoute les feedbacks approuvÃ©s avec leurs poids
3. Fine-tune le modÃ¨le existant
4. Marque les feedbacks comme "used"

## ğŸ”§ Utilisation

### Enregistrer un Feedback

**Frontend :**
```typescript
import { submitFeedback, hashImage } from '@/lib/feedbackService';

const feedbackData = {
  imageHash: await hashImage(imageFile),
  predictedPlantId: 'moringa_oleifera',
  predictedConfidence: 85.5,
  feedbackType: 'correction',
  correctPlantId: 'aloe_vera',
  rating: 2,
  comment: 'Les feuilles sont diffÃ©rentes'
};

await submitFeedback(feedbackData, imageFile);
```

**API :**
```bash
POST /api/feedback
Content-Type: multipart/form-data

{
  "feedback": {
    "image_hash": "...",
    "predicted_plant_id": "...",
    "feedback_type": "correction",
    "correct_plant_id": "..."
  },
  "image": <file>
}
```

### Curater un Feedback

```bash
POST /api/feedback/{feedback_id}/curate
{
  "status": "approved",
  "curator_notes": "Correction valide",
  "curated_by": "admin"
}
```

### PrÃ©parer le Dataset d'EntraÃ®nement

```bash
GET /api/feedback/training-dataset?min_confidence=0.0&only_approved=true&correction_weight=2.0
```

### RÃ©-entraÃ®ner avec les Feedbacks

```bash
cd backend
python train_with_feedback.py \
  --data-dir data/training_images \
  --min-confidence 0.0 \
  --only-approved \
  --correction-weight 2.0
```

## ğŸ“ˆ Statistiques

RÃ©cupÃ©rer les statistiques sur les feedbacks :

```bash
GET /api/feedback/stats
```

Retourne :
- Nombre total de feedbacks
- RÃ©partition par statut (pending, approved, rejected, used)
- Note moyenne
- Taux de correction
- PrÃ©cision par plante
- Nombre de feedbacks Ã  faible confiance

## ğŸ”„ Pipeline AutomatisÃ©

### Option 1 : Script Cron (RecommandÃ©)

CrÃ©er un script `retrain_periodic.py` :

```python
#!/usr/bin/env python3
"""
Script Ã  exÃ©cuter pÃ©riodiquement (cron) pour rÃ©-entraÃ®ner avec les nouveaux feedbacks
"""

from train_with_feedback import train_with_feedback
from app.services.feedback_service import FeedbackService

# VÃ©rifier s'il y a assez de nouveaux feedbacks
feedback_service = FeedbackService()
stats = feedback_service.get_stats()

if stats.approved_count >= 50:  # Seuil minimum
    print(f"Lancement de l'entraÃ®nement avec {stats.approved_count} feedbacks approuvÃ©s...")
    train_with_feedback(
        original_data_dir="data/training_images",
        min_confidence=0.0,
        only_approved=True,
        correction_weight=2.0
    )
    print("EntraÃ®nement terminÃ©!")
else:
    print(f"Pas assez de feedbacks ({stats.approved_count}/50 minimum)")
```

**Cron job (hebdomadaire) :**
```bash
0 2 * * 0 cd /path/to/backend && python retrain_periodic.py >> logs/retrain.log 2>&1
```

### Option 2 : Webhook/API

CrÃ©er un endpoint admin pour dÃ©clencher manuellement :

```python
@app.post("/api/admin/retrain")
async def trigger_retraining():
    """DÃ©clenche un rÃ©-entraÃ®nement (admin seulement)"""
    # VÃ©rifier les permissions admin
    # Lancer train_with_feedback en arriÃ¨re-plan
    # Retourner un job_id pour suivre la progression
    pass
```

## ğŸ“Š MÃ©triques de SuccÃ¨s

Suivre ces mÃ©triques pour Ã©valuer l'efficacitÃ© :

1. **Taux de correction** : Devrait diminuer avec le temps
2. **Note moyenne** : Devrait augmenter
3. **PrÃ©cision par plante** : Identifier les plantes problÃ©matiques
4. **Feedbacks Ã  faible confiance** : Zones d'amÃ©lioration

## ğŸ›¡ï¸ QualitÃ© des DonnÃ©es

### DÃ©tection de Spam

- Limiter les feedbacks par session/IP
- VÃ©rifier la cohÃ©rence (mÃªme image, feedbacks contradictoires)
- DÃ©tecter les patterns suspects

### Validation

- VÃ©rifier que `correct_plant_id` existe dans la base
- Valider que l'image correspond au hash
- VÃ©rifier les formats et types

## ğŸ” SÃ©curitÃ©

1. **Rate Limiting** : Limiter les soumissions par utilisateur
2. **Validation** : Valider tous les inputs
3. **Curation** : Toujours curater avant d'utiliser pour l'entraÃ®nement
4. **Backup** : Sauvegarder les feedbacks avant rÃ©-entraÃ®nement

## ğŸ“ Exemple de Workflow Complet

1. **Utilisateur identifie une plante** â†’ PrÃ©diction avec 75% confiance
2. **Utilisateur note 2/5** â†’ Feedback enregistrÃ© (pending)
3. **Curateur approuve** â†’ Statut â†’ approved
4. **Pipeline automatique** (hebdomadaire) :
   - Collecte les feedbacks approuvÃ©s
   - PrÃ©pare le dataset avec poids
   - RÃ©-entraÃ®ne le modÃ¨le
   - Marque les feedbacks comme "used"
5. **Nouveau modÃ¨le dÃ©ployÃ©** â†’ Meilleure prÃ©cision sur ce type de plante

## ğŸ“ Bonnes Pratiques

1. **Collecter activement** : Encourager les utilisateurs Ã  donner du feedback
2. **Curater rÃ©guliÃ¨rement** : VÃ©rifier la qualitÃ© avant entraÃ®nement
3. **RÃ©-entraÃ®ner progressivement** : Ne pas tout rÃ©-entraÃ®ner Ã  chaque fois
4. **Monitorer** : Suivre les mÃ©triques et ajuster les poids si nÃ©cessaire
5. **Communiquer** : Informer les utilisateurs que leur feedback amÃ©liore le systÃ¨me

## ğŸš€ Prochaines AmÃ©liorations

- [ ] Interface de curation web
- [ ] DÃ©tection automatique de spam
- [ ] A/B testing des modÃ¨les
- [ ] Dashboard de mÃ©triques
- [ ] Notifications aux contributeurs
- [ ] SystÃ¨me de badges/rÃ©compenses

