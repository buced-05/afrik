# Guide de Configuration Rapide - Backend ivoire.ai

## ğŸš€ DÃ©marrage Rapide

### Windows
```bash
cd backend
start.bat
```

### Linux/Mac
```bash
cd backend
chmod +x start.sh
./start.sh
```

## ğŸ“‹ Configuration Manuelle

### 1. CrÃ©er l'environnement virtuel
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 2. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 3. Configurer les variables d'environnement
```bash
# Copier le fichier d'exemple
cp .env.example .env

# Ã‰diter .env avec vos clÃ©s API
```

### 4. DÃ©marrer l'API
```bash
# Mode dÃ©veloppement (avec rechargement automatique)
uvicorn app.main:app --reload

# Mode production
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

## ğŸ”§ Configuration Requise

### Variables d'environnement (.env)

| Variable | Description | Requis | DÃ©faut |
|----------|-------------|--------|--------|
| `OPENAI_API_KEY` | ClÃ© API OpenAI pour LLM | Non | - |
| `LLM_MODEL` | ModÃ¨le LLM Ã  utiliser | Non | `gpt-4o-mini` |
| `MODEL_PATH` | Chemin vers le modÃ¨le TensorFlow | Non | `models/plant_recognition_model.h5` |
| `PLANT_DB_PATH` | Chemin vers la base de donnÃ©es | Non | `data/plants_database.json` |
| `FRONTEND_URL` | URL du frontend (CORS) | Non | `http://localhost:3000` |
| `PORT` | Port de l'API | Non | `8000` |

## ğŸ“ Structure des Fichiers

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ schemas.py        # SchÃ©mas Pydantic
â”‚   â”‚   â””â”€â”€ feedback_schemas.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ vision_service.py # Service de reconnaissance
â”‚       â”œâ”€â”€ llm_service.py    # Service LLM
â”‚       â””â”€â”€ feedback_service.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ plants_database.json  # Base de donnÃ©es des plantes
â”œâ”€â”€ models/                   # ModÃ¨les TensorFlow (Ã  crÃ©er)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ start.sh                  # Script Linux/Mac
â””â”€â”€ start.bat                 # Script Windows
```

## ğŸ§ª Tester l'API

### VÃ©rifier la santÃ© de l'API
```bash
curl http://localhost:8000/api/health
```

### Documentation interactive
Ouvrir dans le navigateur: `http://localhost:8000/docs`

### Tester l'identification
```bash
curl -X POST "http://localhost:8000/api/identify" \
  -F "file=@path/to/image.jpg" \
  -F "user_intent=medecine"
```

## ğŸ³ Docker

### Construire l'image
```bash
docker build -t ivoire-ai-backend .
```

### Lancer le conteneur
```bash
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=your_key \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  ivoire-ai-backend
```

## ğŸ” Mode Mock

Si le modÃ¨le TensorFlow n'est pas disponible, l'API fonctionne en **mode mock** :
- Retourne des rÃ©sultats simulÃ©s
- Utilise la base de donnÃ©es des plantes si disponible
- Permet le dÃ©veloppement sans modÃ¨le entraÃ®nÃ©

## ğŸ“ Notes

- Le backend fonctionne sans modÃ¨le TensorFlow (mode mock)
- L'API OpenAI est optionnelle (mode mock si non configurÃ©e)
- La base de donnÃ©es des plantes peut Ãªtre crÃ©Ã©e manuellement ou gÃ©nÃ©rÃ©e depuis le frontend

