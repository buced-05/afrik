# Guide de DÃ©marrage Rapide - ivoire.ai

Ce guide vous permet de dÃ©marrer rapidement avec ivoire.ai.

## ğŸš€ DÃ©marrage Rapide (Mode DÃ©veloppement)

### Option 1 : DÃ©marrage Automatique (RecommandÃ©) âš¡

```bash
# Installer les dÃ©pendances frontend
npm install

# Installer les dÃ©pendances backend
npm run backend:install
# OU manuellement:
# cd backend && pip install -r requirements.txt

# DÃ©marrer les deux serveurs en mÃªme temps
npm run dev:all
```

Cette commande dÃ©marre automatiquement :
- âœ… Backend sur `http://localhost:8000`
- âœ… Frontend sur `http://localhost:3000`

### Option 2 : DÃ©marrage Manuel

#### 1. Frontend (Next.js)

```bash
# Installer les dÃ©pendances
npm install

# Lancer le serveur de dÃ©veloppement
npm run dev
```

Le frontend sera accessible sur `http://localhost:3000`

#### 2. Backend (FastAPI)

**Dans un nouveau terminal :**

```bash
# Aller dans le dossier backend
cd backend

# CrÃ©er un environnement virtuel (premiÃ¨re fois seulement)
python -m venv venv

# Activer l'environnement
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Installer les dÃ©pendances (premiÃ¨re fois seulement)
pip install -r requirements.txt

# CrÃ©er le fichier .env (premiÃ¨re fois seulement)
cp .env.example .env
# Ã‰diter .env et ajouter votre OPENAI_API_KEY si vous voulez utiliser le LLM

# Lancer l'API
python -m uvicorn app.main:app --reload
# OU utiliser la commande npm depuis la racine:
# npm run backend
```

Le backend sera accessible sur `http://localhost:8000`

> ğŸ’¡ **Note** : Si le backend n'est pas disponible, l'application fonctionnera en mode mock (offline) automatiquement.

### 3. Tester l'API

```bash
# VÃ©rifier que l'API fonctionne
curl http://localhost:8000/api/health

# Tester l'identification (remplacez image.jpg par votre image)
curl -X POST "http://localhost:8000/api/identify" \
  -F "file=@image.jpg" \
  -F "user_intent=medecine"
```

## ğŸ“¦ DÃ©ploiement avec Docker

### Backend

```bash
cd backend
docker-compose up -d
```

### Frontend

```bash
# Build
npm run build

# Avec Docker (crÃ©er un Dockerfile pour Next.js)
docker build -t ivoire-ai-frontend .
docker run -p 3000:3000 ivoire-ai-frontend
```

## ğŸ§  EntraÃ®ner le ModÃ¨le de Vision

Voir `SETUP_ML.md` pour les instructions dÃ©taillÃ©es.

**RÃ©sumÃ© :**
1. Organiser vos images dans `backend/data/training_images/` (un dossier par classe)
2. Lancer `python backend/train_model.py`
3. Le modÃ¨le sera sauvegardÃ© dans `backend/models/plant_recognition_model.h5`

## ğŸ”§ Configuration

### Variables d'environnement Backend (`.env`)

```env
FRONTEND_URL=http://localhost:3000
MODEL_PATH=models/plant_recognition_model.h5
PLANT_DB_PATH=data/plants_database.json
OPENAI_API_KEY=your_key_here  # Optionnel
LLM_MODEL=gpt-4o-mini
```

### Variables d'environnement Frontend (`.env.local`)

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“± Mode Offline

L'application fonctionne en mode PWA :

1. **PremiÃ¨re visite** : L'application se tÃ©lÃ©charge et s'installe
2. **Mode offline** : 
   - Le modÃ¨le TensorFlow.js est chargÃ© depuis IndexedDB
   - La base de donnÃ©es locale est utilisÃ©e
   - L'identification fonctionne sans connexion

Pour activer le mode offline avec TensorFlow.js :

1. Convertir le modÃ¨le en TensorFlow.js (voir `SETUP_ML.md`)
2. Placer les fichiers dans `public/models/plant_model/`
3. Le modÃ¨le sera automatiquement chargÃ© et mis en cache

## ğŸ§ª Tests

### Backend

```bash
cd backend
pytest tests/  # Si vous avez crÃ©Ã© des tests
```

### Frontend

```bash
npm run lint
npm run build  # VÃ©rifier que le build fonctionne
```

## ğŸ“š Documentation ComplÃ¨te

- **Architecture** : `ARCHITECTURE.md`
- **Configuration ML** : `SETUP_ML.md`
- **Backend** : `backend/README.md`

## ğŸ†˜ ProblÃ¨mes Courants

### Backend ne dÃ©marre pas

- VÃ©rifier que Python 3.11+ est installÃ©
- VÃ©rifier que toutes les dÃ©pendances sont installÃ©es
- VÃ©rifier que le port 8000 n'est pas utilisÃ©

### Frontend ne se connecte pas au backend

- VÃ©rifier que `NEXT_PUBLIC_API_URL` est correct
- VÃ©rifier les CORS dans `backend/app/main.py`
- VÃ©rifier que le backend est bien lancÃ©

### ModÃ¨le non trouvÃ©

- Le backend fonctionne en mode mock si le modÃ¨le n'existe pas
- Pour utiliser le vrai modÃ¨le, voir `SETUP_ML.md`

## ğŸ¯ Prochaines Ã‰tapes

1. âœ… DÃ©marrer le frontend et backend
2. âœ… Tester l'identification (mode mock)
3. ğŸ“¸ Collecter des images de plantes
4. ğŸ§  EntraÃ®ner le modÃ¨le (voir `SETUP_ML.md`)
5. ğŸš€ DÃ©ployer en production

## ğŸ’¡ Astuces

- **DÃ©veloppement** : Utilisez le mode mock pour tester sans modÃ¨le
- **Production** : EntraÃ®nez votre propre modÃ¨le avec vos donnÃ©es
- **Offline** : Convertissez le modÃ¨le en TensorFlow.js pour le navigateur
- **LLM** : Optionnel, mais amÃ©liore l'expÃ©rience utilisateur

